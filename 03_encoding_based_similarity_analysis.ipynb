{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Similarity Analysis using Sentence Transformer Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start similarity analysis...\n",
      "... for Arbonia report\n",
      "... for Firmenich report\n",
      "... for Nestle report\n",
      "Done. Results saved in 00_data/encoding_based_similarity_analysis_results\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import scipy\n",
    "import os\n",
    "import random\n",
    "\n",
    "ENCODINGS_DIRECTORY = '00_data/encoding_results'\n",
    "REPORT_ENCODINGS = (file for file in os.listdir(ENCODINGS_DIRECTORY) if (os.path.isfile(os.path.join(ENCODINGS_DIRECTORY, file)) and file.endswith(\".json\")))\n",
    "QUERY_ENCODINGS = '00_data/encoding_results/all-mpnet-base-v2_query_sentences.json'\n",
    "\n",
    "RESULTS_DIRECTORY = '00_data/encoding_based_similarity_analysis_results'\n",
    "\n",
    "PARSING_METHOD = 'pdfminer'\n",
    "\n",
    "# THRESHOLD defines how big the cosine similarity of a report sentence and a topical sentence should be to be deemed as relevant\n",
    "THRESHOLD = 0.65\n",
    "\n",
    "# SAMPLE can be used to sample from the topical sentences 1 means that all topical sentences should be used\n",
    "# TODO: This repository does not contain yet an analysis of sampled topical sentences\n",
    "SAMPLE = 1\n",
    "         \n",
    "# result is a dictionry that will contain all sentences classified as relevant\n",
    "result = {}\n",
    "\n",
    "print(\"Start similarity analysis...\")\n",
    "\n",
    "# Load topical sentences\n",
    "with open(QUERY_ENCODINGS) as f:\n",
    "    query_encodings = json.load(f)\n",
    "\n",
    "# Sample topical sentences\n",
    "for topic, topic_values in query_encodings.items():\n",
    "    new_vals = random.sample(topic_values, int(len(topic_values)*SAMPLE))\n",
    "    query_encodings[topic] = new_vals\n",
    "\n",
    "# Process all encoded reports\n",
    "for file in REPORT_ENCODINGS:\n",
    "    \n",
    "    # Only use reports with the specified parsing method (pdfminer or easyocr)\n",
    "    if file.split('_')[1] == PARSING_METHOD:\n",
    "        company = file.split('_')[2]\n",
    "        \n",
    "        # add empty dictionary to dictionary result for each company\n",
    "        if company not in result:\n",
    "            result[company] = {}\n",
    "            \n",
    "        print(f\"... for {company} report\")\n",
    "            \n",
    "        # Load encodings of reports\n",
    "        with open('{}/{}'.format(ENCODINGS_DIRECTORY, file)) as f:\n",
    "            company_report_encodings = json.load(f)\n",
    "            \n",
    "            # For each topic, calculate cosine similarity\n",
    "            for topic, topic_values in query_encodings.items():\n",
    "\n",
    "                # Add list to result dictionary for each topic\n",
    "                if topic not in result[company]:\n",
    "                    result[company][topic] = []\n",
    "                \n",
    "                for topic_value in topic_values:   \n",
    "                    \n",
    "                    # Calculate cosine similarity for each sentence in each paragraph\n",
    "                    for paragraph_key, paragraph_values in company_report_encodings.items():\n",
    "                        for sentence_key, sentence_value in paragraph_values.items():\n",
    "\n",
    "                            # Calculate cosine similarity\n",
    "                            distance = scipy.spatial.distance.cdist([topic_value], [sentence_value], \"cosine\")[0]\n",
    "\n",
    "                            # Add sentence to results if cosine similarity is above threshold\n",
    "                            score = 1-distance[0]\n",
    "                            if score > THRESHOLD:\n",
    "                                result[company][topic].append((paragraph_key, sentence_key, score))\n",
    "\n",
    "# Save results to a dictionary\n",
    "with open('{}/{}_{}_th={}_sample={}.json'.format(RESULTS_DIRECTORY, PARSING_METHOD, 'found_sentences', THRESHOLD, SAMPLE), 'w') as f:\n",
    "    json.dump(result, f, indent=4)\n",
    "\n",
    "print(f\"Done. Results saved in {RESULTS_DIRECTORY}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentence-tranformer-based-text-classifier-v9DLVhDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "699fffafd8210b9e4d385c95525aa3103f74d5a70210565d702f2074deeb0b89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
