{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing of Sustainability Reports in PDF format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "\n",
    "REPORT_DIRECTORY = './00_data/reports'\n",
    "REPORTS = os.listdir(REPORT_DIRECTORY)\n",
    "PARSING_RESULTS_DIRECTORY = '00_data/parsing_results'\n",
    "IMAGES = '00_data/parsing_results/pdf_images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing with pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "def cleanse(text):\n",
    "    return re.sub(' +', ' ', text.strip())\n",
    "    \n",
    "def parse_pdf_pdfminer(file):\n",
    "    # Read pdf using pdfminer\n",
    "    text = extract_text(file)\n",
    "\n",
    "    # Paragraphs are delimited by double newlines\n",
    "    paragraphs = {}\n",
    "    paragraph_index = 0\n",
    "\n",
    "    # Add each paragraph with its index to a dict\n",
    "    for paragraph in text.split('\\n\\n'):\n",
    "        paragraph = cleanse(paragraph)\n",
    "        sentences = paragraph.split('.')\n",
    "        if len(sentences) > 0:\n",
    "            sentence_index = 0\n",
    "            for sentence in paragraph.split('.'):\n",
    "                sentence = sentence + '.'\n",
    "                if paragraph_index not in paragraphs:\n",
    "                    paragraphs[paragraph_index] = {}\n",
    "                \n",
    "                paragraphs[paragraph_index][sentence_index] = sentence\n",
    "                sentence_index += 1\n",
    "\n",
    "            paragraph_index += 1\n",
    "\n",
    "    return paragraphs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for file in REPORTS:\n",
    "    print('{}/{}'.format(REPORT_DIRECTORY, file))\n",
    "    parsed_text = parse_pdf_pdfminer('{}/{}'.format(REPORT_DIRECTORY, file), )\n",
    "\n",
    "    with open('{}/{}_{}.json'.format(PARSING_RESULTS_DIRECTORY, 'pdfminer', file[:-4]), 'w') as f:\n",
    "        json.dump(parsed_text, f, indent=4)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing with OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2jpg import pdf2jpg\n",
    "import easyocr\n",
    "\n",
    "def cleanse(text):\n",
    "    return re.sub(' +', ' ', text)\n",
    "\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "for file in REPORTS:\n",
    "    print('{}/{}'.format(REPORT_DIRECTORY, file))\n",
    "\n",
    "    result = pdf2jpg.convert_pdf2jpg('{}/{}'.format(REPORT_DIRECTORY, file), IMAGES, dpi=300, pages='ALL')\n",
    "\n",
    "    paragraphs = {}\n",
    "    paragraph_index = 0\n",
    "\n",
    "    for img in os.listdir('{}/{}_dir'.format(IMAGES, file)):\n",
    "        text = reader.readtext('{}/{}_dir/{}'.format(IMAGES, file, img), paragraph=True)\n",
    "        for paragraph in text:\n",
    "            paragraph = cleanse(paragraph[1])\n",
    "            sentence_index = 0\n",
    "            for sentence in paragraph.split('.'):\n",
    "                sentence = sentence + '.'\n",
    "                if paragraph_index not in paragraphs:\n",
    "                    paragraphs[paragraph_index] = {}\n",
    "                \n",
    "                paragraphs[paragraph_index][sentence_index] = sentence\n",
    "                sentence_index += 1\n",
    "\n",
    "            paragraph_index += 1\n",
    "\n",
    "    with open('{}/{}_{}.json'.format(PARSING_RESULTS_DIRECTORY, 'easyocr', file[:-4]), 'w') as f:\n",
    "        json.dump(paragraphs, f, indent=4)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentence-tranformer-based-text-classifier-nWm91RqC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (main, Oct 13 2022, 09:48:40) [Clang 14.0.0 (clang-1400.0.29.102)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8e82d51497d044bae6e664cc29960b706a3eb7ed2e9e21e37f7ef33c95f3f140"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
