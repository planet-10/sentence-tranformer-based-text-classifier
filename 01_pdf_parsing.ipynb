{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing of Sustainability Reports in PDF format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "\n",
    "REPORT_DIRECTORY = './00_data/reports'\n",
    "REPORTS = os.listdir(REPORT_DIRECTORY)\n",
    "PARSING_RESULTS_DIRECTORY = '00_data/parsing_results'\n",
    "IMAGES = '00_data/parsing_results/pdf_images'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing with pdfminer.six"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdfminer.high_level import extract_text\n",
    "\n",
    "def cleanse(text):\n",
    "    # TODO:\n",
    "    # A lot of cleansing could be done, e.g. \n",
    "    # - unifying different encodings \n",
    "    # - removing special characters\n",
    "    # - concatenating hyphened words, sentences and paragraphs\n",
    "\n",
    "    # Remove leading spaces from texts\n",
    "    return re.sub(' +', ' ', text.strip())\n",
    "    \n",
    "def parse_pdf_pdfminer(file):\n",
    "    # Read pdf using pdfminer\n",
    "    text = extract_text(file)\n",
    "\n",
    "    # Paragraphs are delimited by double newlines\n",
    "    paragraphs = {}\n",
    "    paragraph_index = 0\n",
    "\n",
    "    # Add each paragraph with its index to a dict\n",
    "    for paragraph in text.split('\\n\\n'):\n",
    "\n",
    "        # Cleanse text\n",
    "        paragraph = cleanse(paragraph)\n",
    "\n",
    "        # Split text by dots to extract sentences\n",
    "        # Only use sentences if it does not come from an empty block\n",
    "        sentences = paragraph.split('.')\n",
    "        if len(sentences) > 0:\n",
    "            sentence_index = 0\n",
    "            for sentence in paragraph.split('.'):\n",
    "                sentence = sentence + '.'\n",
    "\n",
    "                # Add sentence to dictionary with a paragraph index and a sentence index\n",
    "                if paragraph_index not in paragraphs:\n",
    "                    paragraphs[paragraph_index] = {}\n",
    "                \n",
    "                paragraphs[paragraph_index][sentence_index] = sentence\n",
    "                sentence_index += 1\n",
    "\n",
    "            paragraph_index += 1\n",
    "\n",
    "    return paragraphs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save dictionary to json\n",
    "for file in REPORTS:\n",
    "    print('{}/{}'.format(REPORT_DIRECTORY, file))\n",
    "    parsed_text = parse_pdf_pdfminer('{}/{}'.format(REPORT_DIRECTORY, file), )\n",
    "\n",
    "    with open('{}/{}_{}.json'.format(PARSING_RESULTS_DIRECTORY, 'pdfminer', file[:-4]), 'w') as f:\n",
    "        json.dump(parsed_text, f, indent=4)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing with OCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz\n",
    "import easyocr\n",
    "\n",
    "def cleanse(text):\n",
    "    # TODO:\n",
    "    # A lot of cleansing could be done, e.g. \n",
    "    # - unifying different encodings \n",
    "    # - removing special characters\n",
    "    # - concatenating hyphened words, sentences and paragraphs\n",
    "\n",
    "    # Remove leading spaces from texts\n",
    "    return re.sub(' +', ' ', text)\n",
    "\n",
    "# Load model for english language\n",
    "reader = easyocr.Reader(['en'])\n",
    "\n",
    "# This approach has to save each pdf page as an image before it can be processed using OCR\n",
    "# To save the pages as images, we use pyMuPDF. For the OCR part we use easyocr\n",
    "\n",
    "# Set the dpi resolution of the images\n",
    "dpi = 600\n",
    "\n",
    "# Set the zoom of the saved image\n",
    "zoom = dpi / 72\n",
    "magnify = fitz.Matrix(zoom, zoom)\n",
    "\n",
    "# Parse each report\n",
    "for file in REPORTS:\n",
    "    print('{}/{}'.format(REPORT_DIRECTORY, file))\n",
    "\n",
    "    # Save report pages as images\n",
    "    doc = fitz.open('{}/{}'.format(REPORT_DIRECTORY, file))\n",
    "    count = 0\n",
    "    for page in doc:\n",
    "        pix = page.get_pixmap(matrix=magnify)  # render page to an image\n",
    "        pix.save('{}/{}_{:02d}.png'.format(IMAGES, file, count))\n",
    "        count += 1\n",
    "\n",
    "    paragraphs = {}\n",
    "    paragraph_index = 0\n",
    "\n",
    "    # Use OCR on each page\n",
    "    for img in [x for x in os.listdir('{}'.format(IMAGES)) if file in x]:\n",
    "\n",
    "        # easyocr returns a list of paragraphs\n",
    "        text = reader.readtext('{}/{}'.format(IMAGES, img), paragraph=True)\n",
    "\n",
    "        # Cleanse each paragraph, split it into sentences and add it to dictionary\n",
    "        for paragraph in text:\n",
    "\n",
    "            paragraph = cleanse(paragraph[1])\n",
    "            sentence_index = 0\n",
    "            # Split text by dots to extract sentences\n",
    "            for sentence in paragraph.split('.'):\n",
    "                sentence = sentence + '.'\n",
    "                if paragraph_index not in paragraphs:\n",
    "                    paragraphs[paragraph_index] = {}\n",
    "                \n",
    "                # Add sentence to dictionary with a paragraph index and a sentence index\n",
    "                paragraphs[paragraph_index][sentence_index] = sentence\n",
    "                sentence_index += 1\n",
    "\n",
    "            paragraph_index += 1\n",
    "\n",
    "    # Save dictionary to json\n",
    "    with open('{}/{}_{}.json'.format(PARSING_RESULTS_DIRECTORY, 'easyocr', file[:-4]), 'w') as f:\n",
    "        json.dump(paragraphs, f, indent=4)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentence-tranformer-based-text-classifier-v9DLVhDS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1 (tags/v3.10.1:2cd268a, Dec  6 2021, 19:10:37) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "699fffafd8210b9e4d385c95525aa3103f74d5a70210565d702f2074deeb0b89"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
